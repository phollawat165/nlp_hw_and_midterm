{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "HW_KeyValueAttention_TH2EN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1cDcKRZwXCL"
      },
      "source": [
        "# Key-Value Attention Mechanism Homework on Keras: Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with key-value attention mechnism that coverts names of constituency MP candidates in the 2019 Thai general election from Thai script to Roman(Latin) script. E.g. นิยม-->niyom "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy6QYsP4wa-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfebe3b-5a09-4234-8ca1-db8c0d3c6af8"
      },
      "source": [
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-22 03:56:14--  https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf [following]\n",
            "--2021-03-22 03:56:14--  https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98308 (96K) [application/octet-stream]\n",
            "Saving to: ‘thsarabunnew-webfont.ttf’\n",
            "\n",
            "thsarabunnew-webfon 100%[===================>]  96.00K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-03-22 03:56:14 (3.62 MB/s) - ‘thsarabunnew-webfont.ttf’ saved [98308/98308]\n",
            "\n",
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRdbTrQJwXCR"
      },
      "source": [
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq20keO6wXCh"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of constituency MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/dataset_diagram.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8lWBh40wjgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a685f4a4-28ac-4784-c863-3130cb7bd4b7"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-22 03:56:16--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "mp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-03-22 03:56:17 (7.64 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTQk8W4OwXCk"
      },
      "source": [
        "import csv\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        name_th.append(row[0])\n",
        "        name_en.append(row[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVNHVM_FwXCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda06886-84a7-47c1-e5cd-c2251d76a804"
      },
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ไกรสีห์ kraisi\n",
            "พัชรี phatri\n",
            "ธีระ thira\n",
            "วุฒิกร wutthikon\n",
            "ไสว sawai\n",
            "สัมภาษณ์  samphat\n",
            "วศิน wasin\n",
            "ทินวัฒน์ thinwat\n",
            "ศักดินัย sakdinai\n",
            "สุรศักดิ์ surasak\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heMTiM7qwXC2"
      },
      "source": [
        "## Task1: Preprocess dataset for Keras (1 point)\n",
        "* 2 dictionaries for indexing (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)\n",
        "* Be mindful of your pad_sequences \"padding\" hyperparameter. Choose wisely (post-padding vs pre-padding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O5YhjntwXC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d5bc80-26c2-4fb5-c5e0-c85b4c2fb996"
      },
      "source": [
        "#FILL YOUR CODE HERE\n",
        "\n",
        "input_chars = list(set(''.join(name_th)))\n",
        "output_chars = list(set(''.join(name_en)))\n",
        "\n",
        "sorted_input_chars= sorted(input_chars)\n",
        "sorted_output_chars= sorted(output_chars)\n",
        "\n",
        "sorted_input_chars.insert(0,\"<PAD>\") #PADDING for input\n",
        "sorted_output_chars.insert(0,\"<PAD>\") #PADDING for output\n",
        "\n",
        "sorted_output_chars.insert(len(sorted_output_chars),\"</S>\") #end of word for output\n",
        "\n",
        "#Input\n",
        "input_char_to_ix = { ch:i for i,ch in enumerate(sorted_input_chars) }\n",
        "ix_to_input_char = { i:ch for i,ch in enumerate(sorted_input_chars) } #reverse dictionary\n",
        "#Output\n",
        "output_char_to_ix = { ch:i for i,ch in enumerate(sorted_output_chars) }\n",
        "ix_to_output_char = { i:ch for i,ch in enumerate(sorted_output_chars) } #reverse dictionary\n",
        "\n",
        "print(input_char_to_ix)\n",
        "print(output_char_to_ix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<PAD>': 0, ' ': 1, 'ก': 2, 'ข': 3, 'ค': 4, 'ฆ': 5, 'ง': 6, 'จ': 7, 'ฉ': 8, 'ช': 9, 'ซ': 10, 'ฌ': 11, 'ญ': 12, 'ฎ': 13, 'ฏ': 14, 'ฐ': 15, 'ฑ': 16, 'ฒ': 17, 'ณ': 18, 'ด': 19, 'ต': 20, 'ถ': 21, 'ท': 22, 'ธ': 23, 'น': 24, 'บ': 25, 'ป': 26, 'ผ': 27, 'ฝ': 28, 'พ': 29, 'ฟ': 30, 'ภ': 31, 'ม': 32, 'ย': 33, 'ร': 34, 'ล': 35, 'ว': 36, 'ศ': 37, 'ษ': 38, 'ส': 39, 'ห': 40, 'ฬ': 41, 'อ': 42, 'ฮ': 43, 'ะ': 44, 'ั': 45, 'า': 46, 'ำ': 47, 'ิ': 48, 'ี': 49, 'ึ': 50, 'ื': 51, 'ุ': 52, 'ู': 53, 'เ': 54, 'แ': 55, 'โ': 56, 'ใ': 57, 'ไ': 58, '็': 59, '่': 60, '้': 61, '๊': 62, '๋': 63, '์': 64}\n",
            "{'<PAD>': 0, '-': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'w': 21, 'y': 22, '</S>': 23}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_kd92mCQRn8",
        "outputId": "3858163a-821c-4092-c1e2-b01602f6d6c4"
      },
      "source": [
        "maxIN = len( max(name_th, key=len))\n",
        "maxOUT = len( max(name_en, key=len))\n",
        "\n",
        "X = []\n",
        "for line in name_th:\n",
        "    temp=[]\n",
        "    for char in line:\n",
        "        temp.append(input_char_to_ix[char])\n",
        "    X.append(temp)\n",
        "Y = []\n",
        "for line in name_en:\n",
        "    temp=[]\n",
        "    for char in line:\n",
        "        temp.append(output_char_to_ix[char])\n",
        "    temp.append(output_char_to_ix[\"</S>\"])\n",
        "    Y.append(temp)    \n",
        "\n",
        "X = pad_sequences(X, maxlen=maxIN, padding='pre')\n",
        "Y = pad_sequences(Y, maxlen=maxOUT+1, padding='post')\n",
        "\n",
        "X = to_categorical(X,len(input_char_to_ix))\n",
        "X = X.reshape(len(name_th),maxIN ,len(input_char_to_ix))\n",
        "\n",
        "Y = to_categorical(Y,len(output_char_to_ix))\n",
        "Y = Y.reshape(len(name_en),maxOUT+1 ,len(output_char_to_ix))\n",
        "print(X.shape,Y.shape)\n",
        "print(X[0])\n",
        "print(Y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10887, 20, 65) (10887, 20, 24)\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNqqnkVSwXC-"
      },
      "source": [
        "# Attention Mechanism\n",
        "## Task 2: Code your own (key-value) attention mechnism (1 point)\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* Define global variables\n",
        "* fill code for one_step_attention function\n",
        "* Hint: use keras.layers.Lambda \n",
        "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSdFcuGuwXDB"
      },
      "source": [
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.layers import Lambda\n",
        "def softMaxAxis1(x):\n",
        "    return softmax(x,axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS3Ziti1wXDH"
      },
      "source": [
        "#These are global variables (shared layers)\n",
        "## Fill your code here\n",
        "## you are allowed to use code in the demo as your template.  \n",
        "\n",
        "\n",
        "repeator = RepeatVector(maxIN)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "\n",
        "splitter = Lambda(lambda tensor: tf.split(tensor, num_or_size_splits=2, axis=2))\n",
        "\n",
        "#Attention function###\n",
        "fattn_1 = Dense(10, activation = \"tanh\")\n",
        "fattn_2 = Dense(1, activation = \"relu\")\n",
        "###\n",
        "activator = Activation(softMaxAxis1, name='attention_scores') \n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecNci8x5wXDN"
      },
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "\n",
        "    #Fill code here\n",
        "    #return None # return whatever you need to complete this homework \n",
        "     # Repeat the decoder hidden state to concat with encoder hidden states\n",
        "\n",
        "    s_prev = repeator(s_prev)\n",
        "    key , value = splitter(a)\n",
        "    concat = concatenator([key,s_prev])\n",
        "    # attention function\n",
        "    e = fattn_1(concat)\n",
        "    energies =fattn_2(e)\n",
        "    # calculate attention_scores (softmax)\n",
        "    attention_scores = activator(energies)\n",
        "    #calculate a context vector\n",
        "    context = dotor([attention_scores,value])\n",
        "\n",
        "    return context,attention_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bgSCY3NwXDU"
      },
      "source": [
        "## Task3: Create and train your encoder/decoder model here (1 point)\n",
        "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CVrgh9nwXDV"
      },
      "source": [
        "#FILL CODE HERE\n",
        "n_h = 32 #hidden dimensions for encoder \n",
        "n_s = 64 #hidden dimensions for decoder\n",
        "encoder_LSTM =  Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, len(input_char_to_ix), n_h*2))\n",
        "decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n",
        "output_layer = Dense(len(output_char_to_ix), activation=\"softmax\") #softmax output layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU4xus2ExRvb"
      },
      "source": [
        "def model(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_h -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    vocab_size -- size of the input vocab\n",
        "    output_vocab_size -- size of the output vocab\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model\n",
        "    X = Input(shape=(Tx, vocab_size))\n",
        "    # Define hidden state and cell state for decoder_LSTM_Cell\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = list()\n",
        "    attention_score = list()\n",
        "    #Encoder Bi-LSTM\n",
        "    # h = Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))(X)\n",
        "    h = encoder_LSTM(X)\n",
        "    #Iterate for Ty steps (Decoding)\n",
        "    for t in range(Ty):\n",
        "    \n",
        "        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "        context,attention = one_step_attention(h, s)\n",
        "        attention_score.append(attention)\n",
        "        # Feed the context vector to the decoder LSTM cell\n",
        "        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n",
        "           \n",
        "        # Pass the decoder hidden output to the output layer (softmax)\n",
        "        out = output_layer(s)\n",
        "        \n",
        "        # Append an output list with the current output\n",
        "        outputs.append(out)\n",
        "    \n",
        "    #Create model instance\n",
        "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
        "    modelPlt = Model(inputs=[X,s0,c0],outputs=[outputs,attention_score])\n",
        "\n",
        "    return model,modelPlt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XptuOQj-wXDb"
      },
      "source": [
        "#FIT YOUR MODEL HERE\n",
        "model,modelPlt = model(maxIN, maxOUT+1, n_h, n_s, len(input_char_to_ix), len(output_char_to_ix))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgzrKjqMDZCE",
        "outputId": "b04ebe7a-3bd3-4fa4-fb34-614277dd5b83"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20, 65)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 20, 64)       25088       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 [(None, 20, 32), (No 0           bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 20, 64)       0           s0[0][0]                         \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 96)       0           lambda[0][0]                     \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 lambda[1][0]                     \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 lambda[2][0]                     \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 lambda[3][0]                     \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 lambda[4][0]                     \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 lambda[5][0]                     \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 lambda[6][0]                     \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 lambda[7][0]                     \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 lambda[8][0]                     \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 lambda[9][0]                     \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 lambda[10][0]                    \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 lambda[11][0]                    \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 lambda[12][0]                    \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 lambda[13][0]                    \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 lambda[14][0]                    \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 lambda[15][0]                    \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 lambda[16][0]                    \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 lambda[17][0]                    \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 lambda[18][0]                    \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 lambda[19][0]                    \n",
            "                                                                 repeat_vector[19][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20, 10)       970         concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[9][0]                \n",
            "                                                                 concatenate[10][0]               \n",
            "                                                                 concatenate[11][0]               \n",
            "                                                                 concatenate[12][0]               \n",
            "                                                                 concatenate[13][0]               \n",
            "                                                                 concatenate[14][0]               \n",
            "                                                                 concatenate[15][0]               \n",
            "                                                                 concatenate[16][0]               \n",
            "                                                                 concatenate[17][0]               \n",
            "                                                                 concatenate[18][0]               \n",
            "                                                                 concatenate[19][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[17][0]                     \n",
            "                                                                 dense[18][0]                     \n",
            "                                                                 dense[19][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_scores (Activation)   (None, 20, 1)        0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 dense_1[9][0]                    \n",
            "                                                                 dense_1[10][0]                   \n",
            "                                                                 dense_1[11][0]                   \n",
            "                                                                 dense_1[12][0]                   \n",
            "                                                                 dense_1[13][0]                   \n",
            "                                                                 dense_1[14][0]                   \n",
            "                                                                 dense_1[15][0]                   \n",
            "                                                                 dense_1[16][0]                   \n",
            "                                                                 dense_1[17][0]                   \n",
            "                                                                 dense_1[18][0]                   \n",
            "                                                                 dense_1[19][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 32)        0           attention_scores[0][0]           \n",
            "                                                                 lambda[0][1]                     \n",
            "                                                                 attention_scores[1][0]           \n",
            "                                                                 lambda[1][1]                     \n",
            "                                                                 attention_scores[2][0]           \n",
            "                                                                 lambda[2][1]                     \n",
            "                                                                 attention_scores[3][0]           \n",
            "                                                                 lambda[3][1]                     \n",
            "                                                                 attention_scores[4][0]           \n",
            "                                                                 lambda[4][1]                     \n",
            "                                                                 attention_scores[5][0]           \n",
            "                                                                 lambda[5][1]                     \n",
            "                                                                 attention_scores[6][0]           \n",
            "                                                                 lambda[6][1]                     \n",
            "                                                                 attention_scores[7][0]           \n",
            "                                                                 lambda[7][1]                     \n",
            "                                                                 attention_scores[8][0]           \n",
            "                                                                 lambda[8][1]                     \n",
            "                                                                 attention_scores[9][0]           \n",
            "                                                                 lambda[9][1]                     \n",
            "                                                                 attention_scores[10][0]          \n",
            "                                                                 lambda[10][1]                    \n",
            "                                                                 attention_scores[11][0]          \n",
            "                                                                 lambda[11][1]                    \n",
            "                                                                 attention_scores[12][0]          \n",
            "                                                                 lambda[12][1]                    \n",
            "                                                                 attention_scores[13][0]          \n",
            "                                                                 lambda[13][1]                    \n",
            "                                                                 attention_scores[14][0]          \n",
            "                                                                 lambda[14][1]                    \n",
            "                                                                 attention_scores[15][0]          \n",
            "                                                                 lambda[15][1]                    \n",
            "                                                                 attention_scores[16][0]          \n",
            "                                                                 lambda[16][1]                    \n",
            "                                                                 attention_scores[17][0]          \n",
            "                                                                 lambda[17][1]                    \n",
            "                                                                 attention_scores[18][0]          \n",
            "                                                                 lambda[18][1]                    \n",
            "                                                                 attention_scores[19][0]          \n",
            "                                                                 lambda[19][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 64), (None,  24832       dot[0][0]                        \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[1][2]                     \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[2][2]                     \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[3][2]                     \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[4][2]                     \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[5][2]                     \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[6][2]                     \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[7][2]                     \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[8][2]                     \n",
            "                                                                 dot[10][0]                       \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[9][2]                     \n",
            "                                                                 dot[11][0]                       \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[10][2]                    \n",
            "                                                                 dot[12][0]                       \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[11][2]                    \n",
            "                                                                 dot[13][0]                       \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[12][2]                    \n",
            "                                                                 dot[14][0]                       \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[13][2]                    \n",
            "                                                                 dot[15][0]                       \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[14][2]                    \n",
            "                                                                 dot[16][0]                       \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[15][2]                    \n",
            "                                                                 dot[17][0]                       \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[16][2]                    \n",
            "                                                                 dot[18][0]                       \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[17][2]                    \n",
            "                                                                 dot[19][0]                       \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[18][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 24)           1560        lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[19][0]                    \n",
            "==================================================================================================\n",
            "Total params: 52,461\n",
            "Trainable params: 52,461\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq_mPzYMDblt",
        "outputId": "e09c98fb-ac24-4128-f1bd-ed43782129bd"
      },
      "source": [
        "modelPlt.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20, 65)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 20, 64)       25088       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 [(None, 20, 32), (No 0           bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 20, 64)       0           s0[0][0]                         \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 96)       0           lambda[0][0]                     \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 lambda[1][0]                     \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 lambda[2][0]                     \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 lambda[3][0]                     \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 lambda[4][0]                     \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 lambda[5][0]                     \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 lambda[6][0]                     \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 lambda[7][0]                     \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 lambda[8][0]                     \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 lambda[9][0]                     \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 lambda[10][0]                    \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 lambda[11][0]                    \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 lambda[12][0]                    \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 lambda[13][0]                    \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 lambda[14][0]                    \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 lambda[15][0]                    \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 lambda[16][0]                    \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 lambda[17][0]                    \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 lambda[18][0]                    \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 lambda[19][0]                    \n",
            "                                                                 repeat_vector[19][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20, 10)       970         concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[9][0]                \n",
            "                                                                 concatenate[10][0]               \n",
            "                                                                 concatenate[11][0]               \n",
            "                                                                 concatenate[12][0]               \n",
            "                                                                 concatenate[13][0]               \n",
            "                                                                 concatenate[14][0]               \n",
            "                                                                 concatenate[15][0]               \n",
            "                                                                 concatenate[16][0]               \n",
            "                                                                 concatenate[17][0]               \n",
            "                                                                 concatenate[18][0]               \n",
            "                                                                 concatenate[19][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[17][0]                     \n",
            "                                                                 dense[18][0]                     \n",
            "                                                                 dense[19][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_scores (Activation)   (None, 20, 1)        0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 dense_1[9][0]                    \n",
            "                                                                 dense_1[10][0]                   \n",
            "                                                                 dense_1[11][0]                   \n",
            "                                                                 dense_1[12][0]                   \n",
            "                                                                 dense_1[13][0]                   \n",
            "                                                                 dense_1[14][0]                   \n",
            "                                                                 dense_1[15][0]                   \n",
            "                                                                 dense_1[16][0]                   \n",
            "                                                                 dense_1[17][0]                   \n",
            "                                                                 dense_1[18][0]                   \n",
            "                                                                 dense_1[19][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 32)        0           attention_scores[0][0]           \n",
            "                                                                 lambda[0][1]                     \n",
            "                                                                 attention_scores[1][0]           \n",
            "                                                                 lambda[1][1]                     \n",
            "                                                                 attention_scores[2][0]           \n",
            "                                                                 lambda[2][1]                     \n",
            "                                                                 attention_scores[3][0]           \n",
            "                                                                 lambda[3][1]                     \n",
            "                                                                 attention_scores[4][0]           \n",
            "                                                                 lambda[4][1]                     \n",
            "                                                                 attention_scores[5][0]           \n",
            "                                                                 lambda[5][1]                     \n",
            "                                                                 attention_scores[6][0]           \n",
            "                                                                 lambda[6][1]                     \n",
            "                                                                 attention_scores[7][0]           \n",
            "                                                                 lambda[7][1]                     \n",
            "                                                                 attention_scores[8][0]           \n",
            "                                                                 lambda[8][1]                     \n",
            "                                                                 attention_scores[9][0]           \n",
            "                                                                 lambda[9][1]                     \n",
            "                                                                 attention_scores[10][0]          \n",
            "                                                                 lambda[10][1]                    \n",
            "                                                                 attention_scores[11][0]          \n",
            "                                                                 lambda[11][1]                    \n",
            "                                                                 attention_scores[12][0]          \n",
            "                                                                 lambda[12][1]                    \n",
            "                                                                 attention_scores[13][0]          \n",
            "                                                                 lambda[13][1]                    \n",
            "                                                                 attention_scores[14][0]          \n",
            "                                                                 lambda[14][1]                    \n",
            "                                                                 attention_scores[15][0]          \n",
            "                                                                 lambda[15][1]                    \n",
            "                                                                 attention_scores[16][0]          \n",
            "                                                                 lambda[16][1]                    \n",
            "                                                                 attention_scores[17][0]          \n",
            "                                                                 lambda[17][1]                    \n",
            "                                                                 attention_scores[18][0]          \n",
            "                                                                 lambda[18][1]                    \n",
            "                                                                 attention_scores[19][0]          \n",
            "                                                                 lambda[19][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 64), (None,  24832       dot[0][0]                        \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[1][2]                     \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[2][2]                     \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[3][2]                     \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[4][2]                     \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[5][2]                     \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[6][2]                     \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[7][2]                     \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[8][2]                     \n",
            "                                                                 dot[10][0]                       \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[9][2]                     \n",
            "                                                                 dot[11][0]                       \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[10][2]                    \n",
            "                                                                 dot[12][0]                       \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[11][2]                    \n",
            "                                                                 dot[13][0]                       \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[12][2]                    \n",
            "                                                                 dot[14][0]                       \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[13][2]                    \n",
            "                                                                 dot[15][0]                       \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[14][2]                    \n",
            "                                                                 dot[16][0]                       \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[15][2]                    \n",
            "                                                                 dot[17][0]                       \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[16][2]                    \n",
            "                                                                 dot[18][0]                       \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[17][2]                    \n",
            "                                                                 dot[19][0]                       \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[18][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 24)           1560        lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[19][0]                    \n",
            "==================================================================================================\n",
            "Total params: 52,461\n",
            "Trainable params: 52,461\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiD3E4sYzIbl"
      },
      "source": [
        "opt = Adam(lr= 0.01, clipvalue=0.5)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C2RET9GwXDh"
      },
      "source": [
        "# Thai-Script to Roman-Script Translation\n",
        "* Task 4: Test your model on 5 examples of your choice including your name! (1 point)\n",
        "* Task 5: Show your visualization of attention scores on one of your example (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gON7T2xVwXDk"
      },
      "source": [
        "#task 4\n",
        "#fill your code here\n",
        "s0 = np.zeros((len(name_th), n_s))\n",
        "c0 = np.zeros((len(name_th), n_s))\n",
        "outputs = list(Y.swapaxes(0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCAy68qE3HfT",
        "outputId": "348d2548-bf60-43d5-f9fb-dd27ea9090f1"
      },
      "source": [
        "np.array(outputs).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 10887, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIuVnbF_1JGe",
        "outputId": "cef6f77e-bce4-4d54-8d01-bcd06df84882"
      },
      "source": [
        "model.fit([X, s0, c0], outputs, epochs=20, batch_size=120)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "91/91 [==============================] - 50s 110ms/step - loss: 31.9710 - dense_2_loss: 3.1490 - dense_2_1_loss: 2.9823 - dense_2_2_loss: 3.0735 - dense_2_3_loss: 3.1446 - dense_2_4_loss: 3.1080 - dense_2_5_loss: 2.9945 - dense_2_6_loss: 2.7229 - dense_2_7_loss: 2.2235 - dense_2_8_loss: 1.6880 - dense_2_9_loss: 1.2582 - dense_2_10_loss: 0.9449 - dense_2_11_loss: 0.7216 - dense_2_12_loss: 0.6008 - dense_2_13_loss: 0.5377 - dense_2_14_loss: 0.5004 - dense_2_15_loss: 0.4755 - dense_2_16_loss: 0.4687 - dense_2_17_loss: 0.4629 - dense_2_18_loss: 0.4579 - dense_2_19_loss: 0.4558 - dense_2_accuracy: 0.0436 - dense_2_1_accuracy: 0.1409 - dense_2_2_accuracy: 0.1112 - dense_2_3_accuracy: 0.0722 - dense_2_4_accuracy: 0.0901 - dense_2_5_accuracy: 0.1296 - dense_2_6_accuracy: 0.2169 - dense_2_7_accuracy: 0.3832 - dense_2_8_accuracy: 0.5738 - dense_2_9_accuracy: 0.7197 - dense_2_10_accuracy: 0.8133 - dense_2_11_accuracy: 0.8787 - dense_2_12_accuracy: 0.9105 - dense_2_13_accuracy: 0.9273 - dense_2_14_accuracy: 0.9349 - dense_2_15_accuracy: 0.9399 - dense_2_16_accuracy: 0.9413 - dense_2_17_accuracy: 0.9424 - dense_2_18_accuracy: 0.9431 - dense_2_19_accuracy: 0.9432\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 10s 109ms/step - loss: 22.4021 - dense_2_loss: 2.9208 - dense_2_1_loss: 2.5676 - dense_2_2_loss: 2.7218 - dense_2_3_loss: 2.8095 - dense_2_4_loss: 2.5696 - dense_2_5_loss: 2.3420 - dense_2_6_loss: 2.0494 - dense_2_7_loss: 1.5385 - dense_2_8_loss: 1.1020 - dense_2_9_loss: 0.7242 - dense_2_10_loss: 0.4528 - dense_2_11_loss: 0.2709 - dense_2_12_loss: 0.1497 - dense_2_13_loss: 0.0818 - dense_2_14_loss: 0.0400 - dense_2_15_loss: 0.0247 - dense_2_16_loss: 0.0167 - dense_2_17_loss: 0.0106 - dense_2_18_loss: 0.0057 - dense_2_19_loss: 0.0036 - dense_2_accuracy: 0.0638 - dense_2_1_accuracy: 0.2399 - dense_2_2_accuracy: 0.1941 - dense_2_3_accuracy: 0.1371 - dense_2_4_accuracy: 0.2097 - dense_2_5_accuracy: 0.2898 - dense_2_6_accuracy: 0.3513 - dense_2_7_accuracy: 0.4981 - dense_2_8_accuracy: 0.6382 - dense_2_9_accuracy: 0.7693 - dense_2_10_accuracy: 0.8668 - dense_2_11_accuracy: 0.9228 - dense_2_12_accuracy: 0.9615 - dense_2_13_accuracy: 0.9805 - dense_2_14_accuracy: 0.9904 - dense_2_15_accuracy: 0.9942 - dense_2_16_accuracy: 0.9965 - dense_2_17_accuracy: 0.9975 - dense_2_18_accuracy: 0.9986 - dense_2_19_accuracy: 0.9993\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 10s 110ms/step - loss: 21.3808 - dense_2_loss: 2.7936 - dense_2_1_loss: 2.3507 - dense_2_2_loss: 2.6212 - dense_2_3_loss: 2.7492 - dense_2_4_loss: 2.4910 - dense_2_5_loss: 2.2448 - dense_2_6_loss: 1.9727 - dense_2_7_loss: 1.4944 - dense_2_8_loss: 1.0717 - dense_2_9_loss: 0.7014 - dense_2_10_loss: 0.4112 - dense_2_11_loss: 0.2334 - dense_2_12_loss: 0.1290 - dense_2_13_loss: 0.0642 - dense_2_14_loss: 0.0289 - dense_2_15_loss: 0.0114 - dense_2_16_loss: 0.0054 - dense_2_17_loss: 0.0028 - dense_2_18_loss: 0.0022 - dense_2_19_loss: 0.0015 - dense_2_accuracy: 0.1006 - dense_2_1_accuracy: 0.2781 - dense_2_2_accuracy: 0.1840 - dense_2_3_accuracy: 0.1513 - dense_2_4_accuracy: 0.2185 - dense_2_5_accuracy: 0.3176 - dense_2_6_accuracy: 0.3721 - dense_2_7_accuracy: 0.5178 - dense_2_8_accuracy: 0.6370 - dense_2_9_accuracy: 0.7689 - dense_2_10_accuracy: 0.8736 - dense_2_11_accuracy: 0.9352 - dense_2_12_accuracy: 0.9652 - dense_2_13_accuracy: 0.9850 - dense_2_14_accuracy: 0.9928 - dense_2_15_accuracy: 0.9977 - dense_2_16_accuracy: 0.9987 - dense_2_17_accuracy: 0.9997 - dense_2_18_accuracy: 0.9996 - dense_2_19_accuracy: 0.9996\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 10s 110ms/step - loss: 19.6927 - dense_2_loss: 2.5433 - dense_2_1_loss: 1.9932 - dense_2_2_loss: 2.4267 - dense_2_3_loss: 2.5125 - dense_2_4_loss: 2.3332 - dense_2_5_loss: 2.1156 - dense_2_6_loss: 1.8529 - dense_2_7_loss: 1.3976 - dense_2_8_loss: 0.9979 - dense_2_9_loss: 0.6524 - dense_2_10_loss: 0.4006 - dense_2_11_loss: 0.2214 - dense_2_12_loss: 0.1222 - dense_2_13_loss: 0.0618 - dense_2_14_loss: 0.0297 - dense_2_15_loss: 0.0142 - dense_2_16_loss: 0.0094 - dense_2_17_loss: 0.0047 - dense_2_18_loss: 0.0019 - dense_2_19_loss: 0.0014 - dense_2_accuracy: 0.2741 - dense_2_1_accuracy: 0.3522 - dense_2_2_accuracy: 0.2302 - dense_2_3_accuracy: 0.2186 - dense_2_4_accuracy: 0.2556 - dense_2_5_accuracy: 0.3320 - dense_2_6_accuracy: 0.4066 - dense_2_7_accuracy: 0.5505 - dense_2_8_accuracy: 0.6675 - dense_2_9_accuracy: 0.7826 - dense_2_10_accuracy: 0.8755 - dense_2_11_accuracy: 0.9352 - dense_2_12_accuracy: 0.9647 - dense_2_13_accuracy: 0.9838 - dense_2_14_accuracy: 0.9925 - dense_2_15_accuracy: 0.9967 - dense_2_16_accuracy: 0.9978 - dense_2_17_accuracy: 0.9988 - dense_2_18_accuracy: 0.9997 - dense_2_19_accuracy: 0.9996\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 10s 108ms/step - loss: 17.8184 - dense_2_loss: 2.1109 - dense_2_1_loss: 1.6913 - dense_2_2_loss: 2.2462 - dense_2_3_loss: 2.3001 - dense_2_4_loss: 2.1457 - dense_2_5_loss: 1.9213 - dense_2_6_loss: 1.7091 - dense_2_7_loss: 1.3259 - dense_2_8_loss: 0.9476 - dense_2_9_loss: 0.6283 - dense_2_10_loss: 0.3790 - dense_2_11_loss: 0.1985 - dense_2_12_loss: 0.1053 - dense_2_13_loss: 0.0545 - dense_2_14_loss: 0.0264 - dense_2_15_loss: 0.0132 - dense_2_16_loss: 0.0067 - dense_2_17_loss: 0.0043 - dense_2_18_loss: 0.0023 - dense_2_19_loss: 0.0017 - dense_2_accuracy: 0.3520 - dense_2_1_accuracy: 0.4168 - dense_2_2_accuracy: 0.2839 - dense_2_3_accuracy: 0.2740 - dense_2_4_accuracy: 0.2958 - dense_2_5_accuracy: 0.3926 - dense_2_6_accuracy: 0.4266 - dense_2_7_accuracy: 0.5572 - dense_2_8_accuracy: 0.6719 - dense_2_9_accuracy: 0.7911 - dense_2_10_accuracy: 0.8789 - dense_2_11_accuracy: 0.9393 - dense_2_12_accuracy: 0.9697 - dense_2_13_accuracy: 0.9850 - dense_2_14_accuracy: 0.9928 - dense_2_15_accuracy: 0.9971 - dense_2_16_accuracy: 0.9985 - dense_2_17_accuracy: 0.9989 - dense_2_18_accuracy: 0.9996 - dense_2_19_accuracy: 0.9997\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 10s 110ms/step - loss: 16.1286 - dense_2_loss: 1.7281 - dense_2_1_loss: 1.3362 - dense_2_2_loss: 2.0033 - dense_2_3_loss: 2.1719 - dense_2_4_loss: 2.0375 - dense_2_5_loss: 1.8263 - dense_2_6_loss: 1.5890 - dense_2_7_loss: 1.2095 - dense_2_8_loss: 0.8718 - dense_2_9_loss: 0.5652 - dense_2_10_loss: 0.3577 - dense_2_11_loss: 0.1945 - dense_2_12_loss: 0.1102 - dense_2_13_loss: 0.0588 - dense_2_14_loss: 0.0320 - dense_2_15_loss: 0.0172 - dense_2_16_loss: 0.0109 - dense_2_17_loss: 0.0049 - dense_2_18_loss: 0.0022 - dense_2_19_loss: 0.0014 - dense_2_accuracy: 0.4664 - dense_2_1_accuracy: 0.5292 - dense_2_2_accuracy: 0.3462 - dense_2_3_accuracy: 0.3088 - dense_2_4_accuracy: 0.3236 - dense_2_5_accuracy: 0.4206 - dense_2_6_accuracy: 0.4696 - dense_2_7_accuracy: 0.5930 - dense_2_8_accuracy: 0.6957 - dense_2_9_accuracy: 0.8070 - dense_2_10_accuracy: 0.8809 - dense_2_11_accuracy: 0.9330 - dense_2_12_accuracy: 0.9669 - dense_2_13_accuracy: 0.9816 - dense_2_14_accuracy: 0.9910 - dense_2_15_accuracy: 0.9954 - dense_2_16_accuracy: 0.9967 - dense_2_17_accuracy: 0.9983 - dense_2_18_accuracy: 0.9996 - dense_2_19_accuracy: 0.9997\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 10s 111ms/step - loss: 14.4334 - dense_2_loss: 1.3537 - dense_2_1_loss: 0.9976 - dense_2_2_loss: 1.6865 - dense_2_3_loss: 1.9946 - dense_2_4_loss: 1.8843 - dense_2_5_loss: 1.7148 - dense_2_6_loss: 1.5088 - dense_2_7_loss: 1.1530 - dense_2_8_loss: 0.8395 - dense_2_9_loss: 0.5529 - dense_2_10_loss: 0.3430 - dense_2_11_loss: 0.1893 - dense_2_12_loss: 0.1035 - dense_2_13_loss: 0.0593 - dense_2_14_loss: 0.0267 - dense_2_15_loss: 0.0121 - dense_2_16_loss: 0.0073 - dense_2_17_loss: 0.0037 - dense_2_18_loss: 0.0016 - dense_2_19_loss: 9.3811e-04 - dense_2_accuracy: 0.5711 - dense_2_1_accuracy: 0.6539 - dense_2_2_accuracy: 0.4299 - dense_2_3_accuracy: 0.3534 - dense_2_4_accuracy: 0.3859 - dense_2_5_accuracy: 0.4472 - dense_2_6_accuracy: 0.5009 - dense_2_7_accuracy: 0.6002 - dense_2_8_accuracy: 0.7144 - dense_2_9_accuracy: 0.8161 - dense_2_10_accuracy: 0.8854 - dense_2_11_accuracy: 0.9385 - dense_2_12_accuracy: 0.9658 - dense_2_13_accuracy: 0.9846 - dense_2_14_accuracy: 0.9919 - dense_2_15_accuracy: 0.9971 - dense_2_16_accuracy: 0.9982 - dense_2_17_accuracy: 0.9990 - dense_2_18_accuracy: 0.9996 - dense_2_19_accuracy: 0.9998\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 10s 109ms/step - loss: 13.1371 - dense_2_loss: 1.0281 - dense_2_1_loss: 0.8038 - dense_2_2_loss: 1.4898 - dense_2_3_loss: 1.7738 - dense_2_4_loss: 1.7787 - dense_2_5_loss: 1.6248 - dense_2_6_loss: 1.4663 - dense_2_7_loss: 1.1188 - dense_2_8_loss: 0.8206 - dense_2_9_loss: 0.5302 - dense_2_10_loss: 0.3211 - dense_2_11_loss: 0.1713 - dense_2_12_loss: 0.0880 - dense_2_13_loss: 0.0506 - dense_2_14_loss: 0.0311 - dense_2_15_loss: 0.0181 - dense_2_16_loss: 0.0122 - dense_2_17_loss: 0.0057 - dense_2_18_loss: 0.0025 - dense_2_19_loss: 0.0016 - dense_2_accuracy: 0.7018 - dense_2_1_accuracy: 0.7287 - dense_2_2_accuracy: 0.5097 - dense_2_3_accuracy: 0.4415 - dense_2_4_accuracy: 0.4352 - dense_2_5_accuracy: 0.4769 - dense_2_6_accuracy: 0.5213 - dense_2_7_accuracy: 0.6161 - dense_2_8_accuracy: 0.7150 - dense_2_9_accuracy: 0.8163 - dense_2_10_accuracy: 0.8874 - dense_2_11_accuracy: 0.9393 - dense_2_12_accuracy: 0.9697 - dense_2_13_accuracy: 0.9857 - dense_2_14_accuracy: 0.9910 - dense_2_15_accuracy: 0.9955 - dense_2_16_accuracy: 0.9968 - dense_2_17_accuracy: 0.9985 - dense_2_18_accuracy: 0.9995 - dense_2_19_accuracy: 0.9999\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 10s 111ms/step - loss: 11.8201 - dense_2_loss: 0.7456 - dense_2_1_loss: 0.6732 - dense_2_2_loss: 1.3227 - dense_2_3_loss: 1.5904 - dense_2_4_loss: 1.6190 - dense_2_5_loss: 1.5088 - dense_2_6_loss: 1.3508 - dense_2_7_loss: 1.0357 - dense_2_8_loss: 0.7762 - dense_2_9_loss: 0.5112 - dense_2_10_loss: 0.3166 - dense_2_11_loss: 0.1740 - dense_2_12_loss: 0.0928 - dense_2_13_loss: 0.0520 - dense_2_14_loss: 0.0264 - dense_2_15_loss: 0.0121 - dense_2_16_loss: 0.0070 - dense_2_17_loss: 0.0033 - dense_2_18_loss: 0.0016 - dense_2_19_loss: 9.4317e-04 - dense_2_accuracy: 0.8079 - dense_2_1_accuracy: 0.7744 - dense_2_2_accuracy: 0.5836 - dense_2_3_accuracy: 0.4986 - dense_2_4_accuracy: 0.4771 - dense_2_5_accuracy: 0.5180 - dense_2_6_accuracy: 0.5564 - dense_2_7_accuracy: 0.6514 - dense_2_8_accuracy: 0.7317 - dense_2_9_accuracy: 0.8267 - dense_2_10_accuracy: 0.8950 - dense_2_11_accuracy: 0.9440 - dense_2_12_accuracy: 0.9704 - dense_2_13_accuracy: 0.9842 - dense_2_14_accuracy: 0.9921 - dense_2_15_accuracy: 0.9967 - dense_2_16_accuracy: 0.9981 - dense_2_17_accuracy: 0.9991 - dense_2_18_accuracy: 0.9997 - dense_2_19_accuracy: 0.9999\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 10s 111ms/step - loss: 10.4146 - dense_2_loss: 0.5552 - dense_2_1_loss: 0.5751 - dense_2_2_loss: 1.1335 - dense_2_3_loss: 1.4264 - dense_2_4_loss: 1.4167 - dense_2_5_loss: 1.3522 - dense_2_6_loss: 1.2148 - dense_2_7_loss: 0.9576 - dense_2_8_loss: 0.7008 - dense_2_9_loss: 0.4697 - dense_2_10_loss: 0.2818 - dense_2_11_loss: 0.1580 - dense_2_12_loss: 0.0848 - dense_2_13_loss: 0.0463 - dense_2_14_loss: 0.0215 - dense_2_15_loss: 0.0106 - dense_2_16_loss: 0.0055 - dense_2_17_loss: 0.0024 - dense_2_18_loss: 0.0011 - dense_2_19_loss: 7.1850e-04 - dense_2_accuracy: 0.8631 - dense_2_1_accuracy: 0.8156 - dense_2_2_accuracy: 0.6349 - dense_2_3_accuracy: 0.5562 - dense_2_4_accuracy: 0.5479 - dense_2_5_accuracy: 0.5711 - dense_2_6_accuracy: 0.6088 - dense_2_7_accuracy: 0.6846 - dense_2_8_accuracy: 0.7619 - dense_2_9_accuracy: 0.8409 - dense_2_10_accuracy: 0.9071 - dense_2_11_accuracy: 0.9468 - dense_2_12_accuracy: 0.9713 - dense_2_13_accuracy: 0.9840 - dense_2_14_accuracy: 0.9931 - dense_2_15_accuracy: 0.9974 - dense_2_16_accuracy: 0.9986 - dense_2_17_accuracy: 0.9991 - dense_2_18_accuracy: 0.9999 - dense_2_19_accuracy: 0.9999\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 10s 111ms/step - loss: 9.6939 - dense_2_loss: 0.4693 - dense_2_1_loss: 0.5164 - dense_2_2_loss: 1.0233 - dense_2_3_loss: 1.3115 - dense_2_4_loss: 1.3263 - dense_2_5_loss: 1.2617 - dense_2_6_loss: 1.1421 - dense_2_7_loss: 0.9011 - dense_2_8_loss: 0.6776 - dense_2_9_loss: 0.4634 - dense_2_10_loss: 0.2784 - dense_2_11_loss: 0.1551 - dense_2_12_loss: 0.0857 - dense_2_13_loss: 0.0440 - dense_2_14_loss: 0.0200 - dense_2_15_loss: 0.0092 - dense_2_16_loss: 0.0050 - dense_2_17_loss: 0.0022 - dense_2_18_loss: 0.0012 - dense_2_19_loss: 5.7369e-04 - dense_2_accuracy: 0.8761 - dense_2_1_accuracy: 0.8262 - dense_2_2_accuracy: 0.6783 - dense_2_3_accuracy: 0.5948 - dense_2_4_accuracy: 0.5796 - dense_2_5_accuracy: 0.5964 - dense_2_6_accuracy: 0.6360 - dense_2_7_accuracy: 0.7036 - dense_2_8_accuracy: 0.7699 - dense_2_9_accuracy: 0.8410 - dense_2_10_accuracy: 0.9048 - dense_2_11_accuracy: 0.9462 - dense_2_12_accuracy: 0.9703 - dense_2_13_accuracy: 0.9847 - dense_2_14_accuracy: 0.9937 - dense_2_15_accuracy: 0.9973 - dense_2_16_accuracy: 0.9983 - dense_2_17_accuracy: 0.9993 - dense_2_18_accuracy: 0.9998 - dense_2_19_accuracy: 0.9999\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 10s 110ms/step - loss: 8.8236 - dense_2_loss: 0.3978 - dense_2_1_loss: 0.4744 - dense_2_2_loss: 0.9291 - dense_2_3_loss: 1.1917 - dense_2_4_loss: 1.2254 - dense_2_5_loss: 1.1657 - dense_2_6_loss: 1.0270 - dense_2_7_loss: 0.8183 - dense_2_8_loss: 0.6186 - dense_2_9_loss: 0.4048 - dense_2_10_loss: 0.2494 - dense_2_11_loss: 0.1490 - dense_2_12_loss: 0.0824 - dense_2_13_loss: 0.0428 - dense_2_14_loss: 0.0223 - dense_2_15_loss: 0.0126 - dense_2_16_loss: 0.0057 - dense_2_17_loss: 0.0039 - dense_2_18_loss: 0.0022 - dense_2_19_loss: 6.9347e-04 - dense_2_accuracy: 0.8956 - dense_2_1_accuracy: 0.8413 - dense_2_2_accuracy: 0.7131 - dense_2_3_accuracy: 0.6413 - dense_2_4_accuracy: 0.6082 - dense_2_5_accuracy: 0.6284 - dense_2_6_accuracy: 0.6746 - dense_2_7_accuracy: 0.7331 - dense_2_8_accuracy: 0.7927 - dense_2_9_accuracy: 0.8663 - dense_2_10_accuracy: 0.9192 - dense_2_11_accuracy: 0.9487 - dense_2_12_accuracy: 0.9723 - dense_2_13_accuracy: 0.9849 - dense_2_14_accuracy: 0.9920 - dense_2_15_accuracy: 0.9957 - dense_2_16_accuracy: 0.9985 - dense_2_17_accuracy: 0.9989 - dense_2_18_accuracy: 0.9995 - dense_2_19_accuracy: 0.9998\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 10s 111ms/step - loss: 8.2211 - dense_2_loss: 0.3478 - dense_2_1_loss: 0.4391 - dense_2_2_loss: 0.8329 - dense_2_3_loss: 1.0965 - dense_2_4_loss: 1.1118 - dense_2_5_loss: 1.0612 - dense_2_6_loss: 0.9610 - dense_2_7_loss: 0.7800 - dense_2_8_loss: 0.5896 - dense_2_9_loss: 0.4044 - dense_2_10_loss: 0.2645 - dense_2_11_loss: 0.1567 - dense_2_12_loss: 0.0836 - dense_2_13_loss: 0.0439 - dense_2_14_loss: 0.0229 - dense_2_15_loss: 0.0117 - dense_2_16_loss: 0.0059 - dense_2_17_loss: 0.0039 - dense_2_18_loss: 0.0024 - dense_2_19_loss: 0.0014 - dense_2_accuracy: 0.9106 - dense_2_1_accuracy: 0.8539 - dense_2_2_accuracy: 0.7456 - dense_2_3_accuracy: 0.6677 - dense_2_4_accuracy: 0.6496 - dense_2_5_accuracy: 0.6616 - dense_2_6_accuracy: 0.6843 - dense_2_7_accuracy: 0.7443 - dense_2_8_accuracy: 0.8014 - dense_2_9_accuracy: 0.8642 - dense_2_10_accuracy: 0.9118 - dense_2_11_accuracy: 0.9448 - dense_2_12_accuracy: 0.9707 - dense_2_13_accuracy: 0.9863 - dense_2_14_accuracy: 0.9919 - dense_2_15_accuracy: 0.9960 - dense_2_16_accuracy: 0.9978 - dense_2_17_accuracy: 0.9986 - dense_2_18_accuracy: 0.9992 - dense_2_19_accuracy: 0.9996\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 10s 113ms/step - loss: 7.3251 - dense_2_loss: 0.2879 - dense_2_1_loss: 0.3706 - dense_2_2_loss: 0.7287 - dense_2_3_loss: 0.9973 - dense_2_4_loss: 1.0238 - dense_2_5_loss: 0.9598 - dense_2_6_loss: 0.8452 - dense_2_7_loss: 0.6968 - dense_2_8_loss: 0.5330 - dense_2_9_loss: 0.3665 - dense_2_10_loss: 0.2272 - dense_2_11_loss: 0.1380 - dense_2_12_loss: 0.0735 - dense_2_13_loss: 0.0354 - dense_2_14_loss: 0.0177 - dense_2_15_loss: 0.0097 - dense_2_16_loss: 0.0067 - dense_2_17_loss: 0.0038 - dense_2_18_loss: 0.0021 - dense_2_19_loss: 0.0013 - dense_2_accuracy: 0.9206 - dense_2_1_accuracy: 0.8750 - dense_2_2_accuracy: 0.7829 - dense_2_3_accuracy: 0.7018 - dense_2_4_accuracy: 0.6776 - dense_2_5_accuracy: 0.6938 - dense_2_6_accuracy: 0.7316 - dense_2_7_accuracy: 0.7749 - dense_2_8_accuracy: 0.8234 - dense_2_9_accuracy: 0.8781 - dense_2_10_accuracy: 0.9290 - dense_2_11_accuracy: 0.9546 - dense_2_12_accuracy: 0.9743 - dense_2_13_accuracy: 0.9875 - dense_2_14_accuracy: 0.9933 - dense_2_15_accuracy: 0.9968 - dense_2_16_accuracy: 0.9981 - dense_2_17_accuracy: 0.9988 - dense_2_18_accuracy: 0.9992 - dense_2_19_accuracy: 0.9998\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 10s 112ms/step - loss: 6.5731 - dense_2_loss: 0.2308 - dense_2_1_loss: 0.3463 - dense_2_2_loss: 0.6866 - dense_2_3_loss: 0.8593 - dense_2_4_loss: 0.9053 - dense_2_5_loss: 0.8478 - dense_2_6_loss: 0.7611 - dense_2_7_loss: 0.6448 - dense_2_8_loss: 0.4786 - dense_2_9_loss: 0.3341 - dense_2_10_loss: 0.2067 - dense_2_11_loss: 0.1210 - dense_2_12_loss: 0.0720 - dense_2_13_loss: 0.0401 - dense_2_14_loss: 0.0180 - dense_2_15_loss: 0.0102 - dense_2_16_loss: 0.0062 - dense_2_17_loss: 0.0025 - dense_2_18_loss: 0.0010 - dense_2_19_loss: 6.0677e-04 - dense_2_accuracy: 0.9367 - dense_2_1_accuracy: 0.8880 - dense_2_2_accuracy: 0.7920 - dense_2_3_accuracy: 0.7412 - dense_2_4_accuracy: 0.7212 - dense_2_5_accuracy: 0.7327 - dense_2_6_accuracy: 0.7626 - dense_2_7_accuracy: 0.7943 - dense_2_8_accuracy: 0.8420 - dense_2_9_accuracy: 0.8885 - dense_2_10_accuracy: 0.9317 - dense_2_11_accuracy: 0.9565 - dense_2_12_accuracy: 0.9733 - dense_2_13_accuracy: 0.9860 - dense_2_14_accuracy: 0.9940 - dense_2_15_accuracy: 0.9969 - dense_2_16_accuracy: 0.9982 - dense_2_17_accuracy: 0.9992 - dense_2_18_accuracy: 0.9998 - dense_2_19_accuracy: 0.9998\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 10s 112ms/step - loss: 5.7976 - dense_2_loss: 0.2058 - dense_2_1_loss: 0.2924 - dense_2_2_loss: 0.5898 - dense_2_3_loss: 0.7316 - dense_2_4_loss: 0.7804 - dense_2_5_loss: 0.7509 - dense_2_6_loss: 0.6713 - dense_2_7_loss: 0.5677 - dense_2_8_loss: 0.4328 - dense_2_9_loss: 0.3126 - dense_2_10_loss: 0.1980 - dense_2_11_loss: 0.1184 - dense_2_12_loss: 0.0702 - dense_2_13_loss: 0.0373 - dense_2_14_loss: 0.0187 - dense_2_15_loss: 0.0100 - dense_2_16_loss: 0.0055 - dense_2_17_loss: 0.0025 - dense_2_18_loss: 0.0015 - dense_2_19_loss: 2.9265e-04 - dense_2_accuracy: 0.9443 - dense_2_1_accuracy: 0.9029 - dense_2_2_accuracy: 0.8297 - dense_2_3_accuracy: 0.7878 - dense_2_4_accuracy: 0.7646 - dense_2_5_accuracy: 0.7622 - dense_2_6_accuracy: 0.7935 - dense_2_7_accuracy: 0.8174 - dense_2_8_accuracy: 0.8579 - dense_2_9_accuracy: 0.8944 - dense_2_10_accuracy: 0.9362 - dense_2_11_accuracy: 0.9608 - dense_2_12_accuracy: 0.9770 - dense_2_13_accuracy: 0.9877 - dense_2_14_accuracy: 0.9935 - dense_2_15_accuracy: 0.9971 - dense_2_16_accuracy: 0.9988 - dense_2_17_accuracy: 0.9994 - dense_2_18_accuracy: 0.9997 - dense_2_19_accuracy: 0.9999\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 10s 112ms/step - loss: 5.0838 - dense_2_loss: 0.1760 - dense_2_1_loss: 0.2711 - dense_2_2_loss: 0.5294 - dense_2_3_loss: 0.6369 - dense_2_4_loss: 0.6631 - dense_2_5_loss: 0.6380 - dense_2_6_loss: 0.5710 - dense_2_7_loss: 0.4899 - dense_2_8_loss: 0.3928 - dense_2_9_loss: 0.2841 - dense_2_10_loss: 0.1782 - dense_2_11_loss: 0.1107 - dense_2_12_loss: 0.0661 - dense_2_13_loss: 0.0376 - dense_2_14_loss: 0.0200 - dense_2_15_loss: 0.0104 - dense_2_16_loss: 0.0050 - dense_2_17_loss: 0.0022 - dense_2_18_loss: 7.6623e-04 - dense_2_19_loss: 4.2620e-04 - dense_2_accuracy: 0.9536 - dense_2_1_accuracy: 0.9085 - dense_2_2_accuracy: 0.8423 - dense_2_3_accuracy: 0.8220 - dense_2_4_accuracy: 0.8000 - dense_2_5_accuracy: 0.8083 - dense_2_6_accuracy: 0.8282 - dense_2_7_accuracy: 0.8464 - dense_2_8_accuracy: 0.8744 - dense_2_9_accuracy: 0.9056 - dense_2_10_accuracy: 0.9425 - dense_2_11_accuracy: 0.9628 - dense_2_12_accuracy: 0.9778 - dense_2_13_accuracy: 0.9861 - dense_2_14_accuracy: 0.9938 - dense_2_15_accuracy: 0.9966 - dense_2_16_accuracy: 0.9987 - dense_2_17_accuracy: 0.9993 - dense_2_18_accuracy: 0.9999 - dense_2_19_accuracy: 0.9999\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 10s 113ms/step - loss: 4.4508 - dense_2_loss: 0.1502 - dense_2_1_loss: 0.2381 - dense_2_2_loss: 0.4528 - dense_2_3_loss: 0.5360 - dense_2_4_loss: 0.5632 - dense_2_5_loss: 0.5603 - dense_2_6_loss: 0.5048 - dense_2_7_loss: 0.4431 - dense_2_8_loss: 0.3532 - dense_2_9_loss: 0.2553 - dense_2_10_loss: 0.1649 - dense_2_11_loss: 0.1037 - dense_2_12_loss: 0.0579 - dense_2_13_loss: 0.0317 - dense_2_14_loss: 0.0168 - dense_2_15_loss: 0.0088 - dense_2_16_loss: 0.0048 - dense_2_17_loss: 0.0027 - dense_2_18_loss: 0.0018 - dense_2_19_loss: 5.8767e-04 - dense_2_accuracy: 0.9638 - dense_2_1_accuracy: 0.9208 - dense_2_2_accuracy: 0.8660 - dense_2_3_accuracy: 0.8471 - dense_2_4_accuracy: 0.8324 - dense_2_5_accuracy: 0.8301 - dense_2_6_accuracy: 0.8514 - dense_2_7_accuracy: 0.8636 - dense_2_8_accuracy: 0.8908 - dense_2_9_accuracy: 0.9176 - dense_2_10_accuracy: 0.9469 - dense_2_11_accuracy: 0.9647 - dense_2_12_accuracy: 0.9792 - dense_2_13_accuracy: 0.9885 - dense_2_14_accuracy: 0.9943 - dense_2_15_accuracy: 0.9970 - dense_2_16_accuracy: 0.9987 - dense_2_17_accuracy: 0.9991 - dense_2_18_accuracy: 0.9994 - dense_2_19_accuracy: 0.9998\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 11s 117ms/step - loss: 4.2628 - dense_2_loss: 0.1470 - dense_2_1_loss: 0.2326 - dense_2_2_loss: 0.4159 - dense_2_3_loss: 0.4755 - dense_2_4_loss: 0.5187 - dense_2_5_loss: 0.5281 - dense_2_6_loss: 0.4770 - dense_2_7_loss: 0.4261 - dense_2_8_loss: 0.3503 - dense_2_9_loss: 0.2612 - dense_2_10_loss: 0.1674 - dense_2_11_loss: 0.1123 - dense_2_12_loss: 0.0629 - dense_2_13_loss: 0.0419 - dense_2_14_loss: 0.0236 - dense_2_15_loss: 0.0109 - dense_2_16_loss: 0.0063 - dense_2_17_loss: 0.0029 - dense_2_18_loss: 0.0014 - dense_2_19_loss: 8.4804e-04 - dense_2_accuracy: 0.9646 - dense_2_1_accuracy: 0.9309 - dense_2_2_accuracy: 0.8768 - dense_2_3_accuracy: 0.8627 - dense_2_4_accuracy: 0.8459 - dense_2_5_accuracy: 0.8409 - dense_2_6_accuracy: 0.8593 - dense_2_7_accuracy: 0.8662 - dense_2_8_accuracy: 0.8884 - dense_2_9_accuracy: 0.9168 - dense_2_10_accuracy: 0.9437 - dense_2_11_accuracy: 0.9615 - dense_2_12_accuracy: 0.9800 - dense_2_13_accuracy: 0.9869 - dense_2_14_accuracy: 0.9923 - dense_2_15_accuracy: 0.9964 - dense_2_16_accuracy: 0.9980 - dense_2_17_accuracy: 0.9988 - dense_2_18_accuracy: 0.9999 - dense_2_19_accuracy: 0.9997\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 10s 113ms/step - loss: 3.4928 - dense_2_loss: 0.1138 - dense_2_1_loss: 0.1941 - dense_2_2_loss: 0.3316 - dense_2_3_loss: 0.3793 - dense_2_4_loss: 0.4210 - dense_2_5_loss: 0.4299 - dense_2_6_loss: 0.4030 - dense_2_7_loss: 0.3565 - dense_2_8_loss: 0.2927 - dense_2_9_loss: 0.2149 - dense_2_10_loss: 0.1438 - dense_2_11_loss: 0.0925 - dense_2_12_loss: 0.0553 - dense_2_13_loss: 0.0304 - dense_2_14_loss: 0.0161 - dense_2_15_loss: 0.0095 - dense_2_16_loss: 0.0053 - dense_2_17_loss: 0.0023 - dense_2_18_loss: 6.3728e-04 - dense_2_19_loss: 2.6708e-04 - dense_2_accuracy: 0.9743 - dense_2_1_accuracy: 0.9427 - dense_2_2_accuracy: 0.9022 - dense_2_3_accuracy: 0.8913 - dense_2_4_accuracy: 0.8782 - dense_2_5_accuracy: 0.8677 - dense_2_6_accuracy: 0.8771 - dense_2_7_accuracy: 0.8911 - dense_2_8_accuracy: 0.9081 - dense_2_9_accuracy: 0.9301 - dense_2_10_accuracy: 0.9532 - dense_2_11_accuracy: 0.9677 - dense_2_12_accuracy: 0.9794 - dense_2_13_accuracy: 0.9883 - dense_2_14_accuracy: 0.9950 - dense_2_15_accuracy: 0.9968 - dense_2_16_accuracy: 0.9980 - dense_2_17_accuracy: 0.9991 - dense_2_18_accuracy: 0.9998 - dense_2_19_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd693ec5290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeHkcBXX51ZI",
        "outputId": "79abc923-8db8-4165-ed42-173ec92119b5"
      },
      "source": [
        "def prep_input(input_list):\n",
        "   X = []\n",
        "   for line in input_list:\n",
        "      temp=[]\n",
        "      for char in line:\n",
        "          temp.append(input_char_to_ix[char])\n",
        "      X.append(temp)\n",
        "   X = pad_sequences(X, maxlen=maxIN, padding='pre')\n",
        "   X = to_categorical(X,len(input_char_to_ix))\n",
        "   X = X.reshape(len(input_list),maxIN ,len(input_char_to_ix))\n",
        "    \n",
        "   return X\n",
        "\n",
        "EXAMPLES = ['พลวัต', 'วุฒิกร', 'ศุภกิจ','ชวกร', 'สมชาย']\n",
        "s0 = np.zeros((len(EXAMPLES), n_s))\n",
        "c0 = np.zeros((len(EXAMPLES), n_s))\n",
        "EXAMPLES = prep_input(EXAMPLES)\n",
        "\n",
        "prediction = model.predict([EXAMPLES , s0, c0])\n",
        "prediction = np.swapaxes(prediction,0,1)\n",
        "prediction = np.argmax(prediction, axis = -1)\n",
        "\n",
        "\n",
        "#Y = pad_sequences(Y, maxlen=maxOUT+1, padding='post')\n",
        "for j in range(len(prediction)):\n",
        "    output = \"\".join([ix_to_output_char[int(i)] for i in prediction[j]])\n",
        "    for k in range(len(output)):\n",
        "      if output[k] == \"<\":\n",
        "        break\n",
        "    print(output[:k])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "phonwat\n",
            "wutthikon\n",
            "supphakit\n",
            "chawakon\n",
            "somchai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Tkqgc7HBkk",
        "outputId": "9342ab9d-a85b-4a05-bb09-2cd1d8fdf524"
      },
      "source": [
        "EXAMPLES = ['พลวัต', 'วุฒิกร', 'ศุภกิจ','ชวกร', 'สมชาย']\n",
        "s0 = np.zeros((len(EXAMPLES), n_s))\n",
        "c0 = np.zeros((len(EXAMPLES), n_s))\n",
        "EXAMPLES = prep_input(EXAMPLES)\n",
        "\n",
        "prediction2 = modelPlt.predict([EXAMPLES , s0, c0])\n",
        "prediction2[0] = np.swapaxes(prediction2[0],0,1)\n",
        "prediction2[0] = np.argmax(prediction2[0], axis = -1)\n",
        "print(np.array(prediction2[0]).shape)\n",
        "\n",
        "prediction2[1] = np.swapaxes(prediction2[1],0,1)\n",
        "print(np.array(prediction2[1]).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 20)\n",
            "(5, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-mxbsKwXDp"
      },
      "source": [
        "### Plot the attention map\n",
        "* If you need to install thai font: sudo apt install xfonts-thai\n",
        "* this is what your visualization might look like:\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_viz_sample.png\"  style=\"width: 350px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRL8hHaLwXDq"
      },
      "source": [
        "#task 5\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family']='TH Sarabun New'  #you can change to other font that works for you\n",
        "#fill your code here\n",
        "\n",
        "def pltAtt(word):\n",
        "    pltatt = prediction2[1][word].reshape(20,20)\n",
        "    x_axis = [ix_to_input_char[int(np.argmax(i))] for i in EXAMPLES[word]]\n",
        "    y_axis = [ix_to_output_char[int(i)] for i in prediction2[0][word]]\n",
        "    for i in range(len(y_axis)):\n",
        "      if y_axis[i]==\"</S>\":\n",
        "        y_axis = y_axis[:i]\n",
        "        pltatt = pltatt[:i,:]\n",
        "        break\n",
        "    return sns.heatmap(np.array(pltatt),vmin =0., vmax=1. ,xticklabels = x_axis, yticklabels = y_axis , linewidths=.1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "8W0GdwkwbMfM",
        "outputId": "b11ea634-afdb-48a6-fa6b-0d7e45a0345c"
      },
      "source": [
        "pltAtt(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd672c29610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "7UqwsUl3bEST",
        "outputId": "6f0b156a-e51e-499b-f2f2-033adf34f56a"
      },
      "source": [
        "pltAtt(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd67be14450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}